---
title: "Assignment 3"
author: "Kevin Gardner"
date: "2/28/2022"
output: word_document
---

# ------------------------------------------------
# Following is the link to my GitHub account:
# https://github.com/Kgardner22/64060_-kgardner
# ------------------------------------------------

IMPORT AND PREPARE DATA:
  
Import the UniversalBank.csv file

```{r}

UniversalBank <- read.table('C:/R/MyData/UniversalBank.csv', header = T, sep = ',') 

summary(UniversalBank)

```
Create a copy of the original data file to preserve

```{r}

Original_File <- UniversalBank

```

Load required libraries

```{r}

library(caret)
library(reshape2) #used for melt() and dcast();
library(e1071) #used for naiveBayes(); 

```

Prepare the data by converting predictor and target variable to factors

```{r}

UniversalBank$CreditCard=as.factor(UniversalBank$CreditCard)
UniversalBank$Online=as.factor(UniversalBank$Online)
UniversalBank$Personal.Loan=as.factor(UniversalBank$Personal.Loan)

summary(UniversalBank)

```


We need to divide the data into training (60%) and validation (40%) sets

```{r}

set.seed(64060)

Train_Index <- createDataPartition(UniversalBank$Personal.Loan, p=0.6, list = FALSE) #60% for train data
Train.df <- UniversalBank[Train_Index,]
Validation.df <- UniversalBank[-Train_Index,] #Remaining 40% for validation data

```



REQUIREMENT A:

Create a pivot table for the training data with Online as a column variable, CreditCard as a row variable, and Personal.Loan as a secondary row variable. The values inside the table should convey the count. Use functions melt() and cast(), or function table().


Pivot table created using ftable

```{r}

Table1 <- xtabs(~ CreditCard + Online + Personal.Loan, data=Train.df)
ftable(Table1) 

```

Optional view of this same pivot table using melt();

```{r}

Table1_Long=melt(Table1, measure.vars=c("No", "Yes"), variable.name="Personal.Loan", value.name = "value")
Table1_Long

```

Optional view of this same pivot table using dcast();

```{r}

Table1_Wide = dcast(Table1_Long, CreditCard + Online ~ Personal.Loan, value.var = "value" )
Table1_Wide

```
 
 
REQUIREMENT B:

Looking at the pivot tables created, what is the probability that this customer will accept the loan offer (Personal.Loan=1)?

```{r}
ftable(Table1)
```
P(Personal.Loan=1 | CreditCard=1, Online=1)

  ((59/(479+59)) = (59/538) = 0.1096654

ANSWER: 0.1096654


REQUIREMENT C:

Create two separate pivot tables for the training data. One will have CreditCard (rows) as a function of Personal.Loan (columns) and the other will have Online (rows) as a function of Personal.Loan (columns).

```{r}

table(CreditCard=Train.df$CreditCard, Personal.Loan=Train.df$Personal.Loan)

```

```{r}

table(Online=Train.df$Online, Personal.Loan=Train.df$Personal.Loan)

```


REQUIREMENT D:

Compute the following quantities [P(A|B) means "the probability of A given B"]

i. P(CreditCard=1 | Personal.Loan=1)
    (93/(195+93)) = (93/288) = 0.3229  #Note: I'm using the CreditCard table above
    
    ANSWER = 0.3229

ii. P(Online=1 | Personal.Loan=1)
    (179/(109+179)) = (179/288) = 0.6215  #Note: I'm using the Online table above

    ANSWER = 0.6215
    
iii. P(Personal.Loan=1)
    ((195+93)/(1924+788+195+93)) = (288/3000) = 0.096  #Note: I'm using the CreditCard table above

    ANSWER = 0.096

iv. P(CreditCard=1 | Personal.Loan=0)
    (788/(1924+788)) = (788/2712) = 0.2906  #Note: I'm using the CreditCard table above

    ANSWER = 0.2906

v. P(Online=1 | Personal.Loan=0)
    (1631/(1081+1631)) = (1631/2712) = 0.6014  #Note: I'm using the Online table above
    
    ANSWER = 0.6014
    
vi. P(Personal.Loan=0)
    ((1924+788)/(1924+788+195+93)) = (2712/3000) = 0.904  #Note: I'm using the CreditCard table above
    
    ANSWER = 0.904


REQUIREMENT E:
Use the quantities computed above to compute the naive Bayes probability 
P(Personal.Loan=1 | CreditCard=1, Online=1)

  Using the quantities from the tables generated in requirement C, 
  we can compute the Naive Bayes Calculations as follows:
  
  P = ((93/288)(179/288)(288/3000)) / (((93/288)(179/288)(288/3000))+((788/2712)(1631/2712)(2712/3000)))
  P = (((0.3229167)(0.6215278)(0.096)) / (((0.3229167)(0.6215278)(0.096)) / ((0.2905605)(0.6014012)(0.904)))
  P = 0.0192674 / (0.0192674 + 0.1579681)
  P = 0.0192674 / 0.1772355
  P = 0.1087107
  
  ANSWER = 0.1087107


REQUIREMENT F:
Compare the value calculated in requirement E with the one obtained from the pivot table in requirement B. 

In requirement B, we calculated this as:
  P(Personal.Loan=1 | CreditCard=1, Online=1)
    ((59/(479+59)) = (59/538) = 0.1096654
    This is the Complete (Exact) Bayes Calculation

In requirement E, we calculated this as:
  P = (0.0192674 / 0.1772355) = 0.1087107
    This is the Naive Bayes Calculation as described on page 194 of our textbook.

Which is a more accurate estimate?

  ANSWER = The answer of 0.1096654 calculated in requirement B is more accurate. This is the Complete (Exact) Bayes Calculation that we calculated from the pivot tables. It does not make any assumptions as does the Naive Bayes Calculation in requirement E. Naive Bayes (E) assumes conditional independence while Bayes theorum (B) does not. This being said, Naive Bayes can provide a close estimate and typically, this has very little if any impact on the rank order of the output. 


REQUIREMENT G:
Which of the entries in this table are needed for computing P(Personal.Loan=1 | CreditCard=1, Online=1)?

  ANSWER: The entries in the table needed to compute this are the results where CreditCard=1 and Online=1 showing the results of 479 observations for Personal.Loan=0 and 59 observations for Personal.Loan=1. We do not need the other data in the table. We then compute this by taking 59/(479+59) = 0.1096654.


Run naiveBayes on the data. Examine the model output on training data and find the entry that corresponds to P(Personal.Loan=1 | CreditCard=1, Online=1). Compare this to the number you obtained in requirement E.

```{r}

nb.model<-naiveBayes(Personal.Loan~CreditCard+Online, data=Train.df)
To_Predict=data.frame(CreditCard="1", Online="1")
predict(nb.model, To_Predict, type='raw') #type set to raw to get probabilities;

```
These results show, given CreditCard=1 and Online=1, the probability of the personal loan being accepted (Personal.Loan=1) is 0.1087106.

The number we calculated in requirement E was 0.1087107

There is a slight difference in these numbers due to rounding. 

The niaveBayes model in requirement G computed the same value we manually calculated in requirement E. This Naive Bayes calculation assumes conditional independence while Bayes theorum, calculated in requirement B, does not. Therefore, the Bayes calculation in requirement B (0.1096654) is more accurate. This being said, Naive Bayes can provide a close estimate and typically, this has very little if any impact on the rank order of the output. 






